<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performance and fiability parameters &mdash; Lidi 0.8.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=86f27845" />

  
  
        <script src="_static/jquery.js?v=8dae8fb0"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=486e5634"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Logging" href="logging.html" />
    <link rel="prev" title="Network configuration" href="network.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Lidi
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="gstarted.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="session.html">Session</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameters.html">Command line parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration_file.html">Configuration file</a></li>
<li class="toctree-l1"><a class="reference internal" href="network.html">Network configuration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance and fiability parameters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#throughput-management">Throughput management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rate-limiting">Rate limiting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multithreading">Multithreading</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-affinity">Core affinity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#optimizing-cpu-performances">Optimizing CPU performances</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#packet-sizes">Packet sizes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#block-sizes">Block sizes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#kernel-parameters">Kernel parameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="timers.html">Timers</a></li>
<li class="toctree-l1"><a class="reference internal" href="files.html">Sample applications to exchanging files</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lidi</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Performance and fiability parameters</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/performance.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="performance-and-fiability-parameters">
<h1>Performance and fiability parameters<a class="headerlink" href="#performance-and-fiability-parameters" title="Link to this heading"></a></h1>
<section id="throughput-management">
<h2>Throughput management<a class="headerlink" href="#throughput-management" title="Link to this heading"></a></h2>
<section id="rate-limiting">
<span id="ratelimit"></span><h3>Rate limiting<a class="headerlink" href="#rate-limiting" title="Link to this heading"></a></h3>
<p>Basically, since Lidi diode-send scales pretty well and can reach very high throughput, it is often necessary to ratelimit the speed of diode-send to prevent packet drop in network.
A single thread can send multiple gigabits per second so continuous packet drops can occur very quickly on networks. Once the maximum available bandwidth has be measured, it is important to set this limit in the configuration file :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">sender</span><span class="p">]</span>
<span class="n">max_bandwidth</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Mbit</span><span class="o">/</span><span class="n">s</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This rate limiter tries to match the real bandwith consumption on the network. It includes all overheads due to repair packets and headers. For headers, an assumption is done about the transport layer, which is independant of lidi: the computation is done for packets having Ethernet + IP + UDP headers for a sum of 42 bytes. That means if there are more headers, the real throughput will be higher than what is set in the configuration.</p>
</div>
</section>
<section id="multithreading">
<span id="id1"></span><h3>Multithreading<a class="headerlink" href="#multithreading" title="Link to this heading"></a></h3>
<p>Lidi is designed to reach up to 10Gb/s (or more) on an actual x86 CPU with multiple cores.
Since sending, receiving, encoding and decoding packets are CPU intensive operations, it is necessary to use multiple threads to achieve high throughput.</p>
<p>On sender side, if receiving data from local TCP socket is really fast, encoding and sending packets is quite slow. On a modern x86, each thread can encode and send up to 3 Gb/s of data.</p>
<p>On receiver side, there are 4 processing steps : udp receive, packet reordering, block decoding and tcp send. Of those steps, UDP packet receive thread seems to be the most CPU consumming. Moreover it has real time constraints and must be very fast not to loose any packet.</p>
<p>As we saw, to reach up to 10 Gb/s throughput, it is mandatory to use multiple threads for this operation. To increase Lidi performances and split the load between multiple threads, the <cite>udp_port</cite> configuration must be changed : each port set in this array will spawn a new thread, for the sender and the receiver side.</p>
<p>So to increase the number of threads sending and receiving UDP packets, multiple UDP ports must be used.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">udp_port</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">5000</span> <span class="p">]</span>
</pre></div>
</div>
<p>Default value is 5000. That means diode-send and diode-receive will use 1 thread to transfer data packets. To increase performance, add multiple ports in the configuration file.</p>
</section>
<section id="core-affinity">
<span id="affinity"></span><h3>Core affinity<a class="headerlink" href="#core-affinity" title="Link to this heading"></a></h3>
<p>Due to real time issues at high speed, it could be important to prevent context switch for UDP receiving threads. Thus, it is possible, to use kernel parameter isolcpus and to pin receive threads to a list of CPU cores.</p>
<p>This is explained in many documentation, for instance this <a class="reference external" href="https://linux.enea.com/4.0/documentation/html/book-enea-linux-realtime-guide/#rt--core-isolation">linux realtime guide</a>.</p>
<p>The simple way to do so, is set a list of core in your <a class="reference external" href="https://wiki.linuxfoundation.org/realtime/documentation/howto/tools/cpu-partitioning/isolcpus">linux kernel bootloader parameters</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>isolcpus=&lt;cpu number&gt;,….,&lt;cpu number&gt;
</pre></div>
</div>
<p>Then to configure Lidi <cite>core_affinity</cite> parameter with the same list:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">receiver</span><span class="p">]</span>
<span class="n">core_affinity</span> <span class="o">=</span> <span class="p">[</span> <span class="o">&lt;</span><span class="n">core</span> <span class="n">number</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">core</span> <span class="n">number</span><span class="o">&gt;</span> <span class="p">]</span>
</pre></div>
</div>
<p>This array must have at least the same number of values (core ids) than the number of ports (threads).
There may up to 2 extra core ids to pin both <cite>reorder/decode</cite> and <cite>tcp</cite> threads.
The first extra ID will be assigned to <cite>reorder/decode</cite> thread and the last one will be assigned to <cite>TCP</cite> thread.
See <a class="reference internal" href="#multithreading"><span class="std std-ref">Multithreading</span></a> for more details about UDP RX threads and ports.</p>
</section>
</section>
<section id="optimizing-cpu-performances">
<h2>Optimizing CPU performances<a class="headerlink" href="#optimizing-cpu-performances" title="Link to this heading"></a></h2>
<p>To be transferred through the diode, data is sliced by lidi at different levels:</p>
<blockquote>
<div><ul class="simple">
<li><p>into <cite>packets</cite> at the UDP transfer level.</p></li>
<li><p>into <cite>blocks</cite> at the logical fountain codes level,</p></li>
</ul>
</div></blockquote>
<p>One can have effect on the slicing sizes to achieve optimal performances by using several command line options.</p>
<section id="packet-sizes">
<span id="mtu"></span><h3>Packet sizes<a class="headerlink" href="#packet-sizes" title="Link to this heading"></a></h3>
<p>Firstly, the parameter which has the biggest impact on the network and the CPU load is the packet size.
If possible, MTU on the UDP interface should be increased, and must be set to the same value on sender and receiver sides:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">udp_mtu</span> <span class="o">=</span> <span class="mi">1500</span>
</pre></div>
</div>
<p>Default MTU is set to 1500 (default MTU on ethernet interfaces) and should be increased. A higher value will reduce a lot the number of packets to manage in the kernel.
Of course, this number should not exeed network interface parameter or packet fragmentation will occur before sending the packet and the benefits of this parameter will be lost.</p>
<p>Try to adjust to 9000 if possible on the network, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ip link set dev &lt;myinterface&gt; mtu 9000
</pre></div>
</div>
</section>
<section id="block-sizes">
<span id="raptorq"></span><h3>Block sizes<a class="headerlink" href="#block-sizes" title="Link to this heading"></a></h3>
<p>Then, on the logical level, fountain code operate on blocks. Blocks have fixed size and will be split in IP packets to be sent on the network.
Blocks are made of two parts : encoding block and repair block. Encoding block contains original data. Repair block is optional and represents redundancy : they are used by fountain codes to ensure data reconstruction.</p>
<p>On both sides, parameters have the same name and must be set to the same values.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_block_size</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">nb_bytes</span><span class="o">&gt;</span>

<span class="n">repair_block_size</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">nb_bytes</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The default value for an encoding block is 60000 and repair block size is 6000 (10% of encoding block value). This mean we have 10% of data overhead on all transfers. But this allows to have small packet loss or corruption and still being able to reconstruct the original block.</p>
<p>It is possible to increase or decrease <cite>encoding_block_size</cite> according to the average size of data sessions. If sessions are small, a small value will limit the overhead. If sessions are big, increasing the value can improve performances.</p>
<p>The option repair_block_size can be adjust regarding the quality of the network. If there is a network overload, a lot of packets will be dropped and we can expect loosing the current session. This parameter helps to prevent data loss when a small data corruption occurs: by default, the kernel will drop corrupted packets. It is important to configure at least a couple of repair packets not to loose a full session due to data corruption.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>RaptorQ algorithm is able to fix corrupted data thanks to repair packets, so theorically it would be possible to disable UDP kernel checksum and let Lidi process them. But if there are too many corruption or if no repair packet is received, RaptorQ will not be able to detect the corruption and will decode and send corrupted blocks. So for most cases, it looks better to keep kernel UDP checksum and have a block decoding failure when too many packets are missing or corrupted.</p>
</div>
<p>To prevent more overhead when mapping blocks on packets, encoding block and repair block must match a factor of the defined UDP MTU. The exact algorithm is : defined mtu - ip header size (20) - udp header size (8) - raptor header size (4) - lidi protocol header size (4).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the repair_block_size is inferior to a single packet size (see mtu), no repair block will be generated.</p>
</div>
</section>
</section>
<section id="kernel-parameters">
<span id="tweaking-parameters"></span><h2>Kernel parameters<a class="headerlink" href="#kernel-parameters" title="Link to this heading"></a></h2>
<p>If you want to run lidi closer to its intended speed, please set the following sysctl to the maximum value (root required):</p>
<p>Mandatory parameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">rmem_max</span><span class="o">=</span><span class="mi">2000000000</span>
</pre></div>
</div>
<p>Optional parameters (to be checked):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">wmem_max</span><span class="o">=</span><span class="mi">67108864</span>
<span class="n">net</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">netdev_max_backlog</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">net</span><span class="o">.</span><span class="n">ipv4</span><span class="o">.</span><span class="n">udp_mem</span><span class="o">=</span><span class="s2">&quot;12148128 16197504 67108864&quot;</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="network.html" class="btn btn-neutral float-left" title="Network configuration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="logging.html" class="btn btn-neutral float-right" title="Logging" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, ANSSI-FR.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>